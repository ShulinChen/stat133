# have the same number of elements
class(year)
ls()
rm(response)
# Install the package "httr", and load it
install.packages("httr")
library(httr)
# now load the data from the github repository of the course
response <- GET(url="https://github.com/gastonstat/stat133/raw/master/datasets/superbowl_teams.RData")
load(rawConnection(response$content))
rm(response)
# inspect the objects with ls()
# (you should be able to see three vectors)
ls()
# year: year of superbowl from 1967 to 2015
# winner: champions
# loser: losing teams
# find the class of each vector (year, winner, loser)
class(year)
class(year)
class(winner)
class(loser)
length(year)
length(winner)
length(loser)
# get the first 5 champions
winner[1:5]
# get the last 5 champions
winner[-5:-1]
# get the last 5 champions
winner[-5:-1]
winner[-5:]
# get the last 5 champions
tail(winner,5)
winner[1:5]
head(winner 5)
winner[1:5]
head(winner, 5)
unique(winner)
count(unique(winner))
length(unique(winner))
sort(winner)
sort(unique(winner))
sort(unique(winner),decreasing = TRUE)
length(null)
length(NULL)
source('~/programming/stat133/lab02/ShulinChen_lab2.R')
sw[sw$height > 2, ]
length(sw[sw$height > 2, ] )
length(sw[sw$height > 2, ] ) > 1
"knife" %in% sw$weapon
length(sw[sw$height > 2, ] ) > 1
source('~/programming/stat133/lab02/ShulinChen_lab2.R')
install.packages("readr")
source('~/programming/stat133/lab02/ShulinChen_lab2.R')
source('~/programming/stat133/lab02/ShulinChen_lab2.R')
install.packages("readr")
# =====================================================
# Stat133: Lab 2
# Author: Gaston Sanchez
# Description: Basics of data frames
# Data: Star Wars characters
# =====================================================
source('~/programming/stat133/lab02/ShulinChen_lab2.R')
source('~/programming/stat133/lab02/ShulinChen_lab2.R')
install.packages("readr")
# To read the data, we'll use the package "readr"
# To install "readr" type:
install.packages("readr")
# Remember that you only need to install a package once
# load "readr
library("readr")
# read data using read_csv()
# (read_csv() does not convert strings into factors)
sw <- read_csv("https://raw.githubusercontent.com/gastonstat/stat133/master/datasets/starwarstoy.csv")
# use str() to get information about the data frame structure
str(sw)
# use summary() to get some descriptive statistics
summary(sw)
# convert column 'gender' as a factor
factor(sw[,2])
log(sw$height[sw$weapon == "blaster" | sw$weapon == "bowcaster"])
# use plot() to make a scatter plot of height and weight
plot(sw$height, sw$weight)
# create a new variable "newvar": height divided by weight
plot(sw$height, sw$weight)
install.packages("readr")
# Remember that you only need to install a package once
# load "readr
library("readr")
# read data using read_csv()
# (read_csv() does not convert strings into factors)
sw <- read_csv("https://raw.githubusercontent.com/gastonstat/stat133/master/datasets/starwarstoy.csv")
# use plot() to make a scatter plot of height and weight
plot(sw$height, sw$weight)
plot(sw$height, sw$weight)
install.packages("readr")
install.packages("readr")
# use plot() to make a scatter plot of height and weight
plot(sw$height, sw$weight)
plot(sw$height, sw$weight)
# create a new variable "newvar": height divided by weight
newvar <- sw$height / sw$weight
# add 'newvar' to the data frame sw
sw$newvar <- newvar
?read.table
# Stat133: HW 1
# Description: Basics of character vectors
# Data: Teams that played the superbowl
# =====================================================
# Please submit your own R script to bcourses
# Write your full name
# Name: Leanne [Yuen] Lee
# SID 23581678
# =====================================================
# Loading the Data in file "superbowl_teams.RData"
# superbowl_teams.RData contains 3 vectors:
# 1) year:   year of superbowl from 1967 to 2015
# 2) winner: champion teams
# 3) loser:  losing teams
# =====================================================
# Start a new R session (in RStudio)
# Install the package "httr", and load it
install.packages("httr")
library(httr)
# now load the data from the github repository of the course
response <- GET(url="https://github.com/gastonstat/stat133/raw/master/datasets/superbowl_teams.RData")
load(rawConnection(response$content))
rm(response)
# inspect the objects with ls()
# (you should be able to see three vectors)
ls()
# year: year of superbowl from 1967 to 2015
ls()
# year: year of superbowl from 1967 to 2015
# winner: champions
# loser: losing teams
# find the class of each vector (year, winner, loser)
class(year)
class(winner)
class(loser)
# use length() to determine whether the three vectors
# have the same number of elements
length(year)
length(winner)
length(loser)
# =====================================================
# Winning teams
# Write the commands to answer the following questions
# =====================================================
# get the first 5 champions
#winner[1:5]
head(winner, 5)
# get the last 5 champions
tail(winner,5)
# how many unique champions?
# sort unique champions alphabetically (from A to Z)
sort(unique(winner))
# decreasingly sort unique champions alphabetically (from Z to A)
sort(unique(winner),decreasing = TRUE)
# get the champions in even positions (2, 4, 6, 8, etc)
?seq
evenSeq <- seq(2, length(winner), by=2)
winner[evenSeq]
# get the champions in odd positions (1, 3, 5, 7, etc)
oddSeq <- seq(1, length(winner), by=2)
winner[oddSeq]
# use the function table() to get a
# table of frequencies for the winning teams
# (assign the table to the object 'win_freqs')
win_freqs <- table(winer)
win_freqs <- table(winner)
win_freqs
which.max(win_freqs)
?which.max
which.max(win_freqs)
max(win_freqs)
table(win_freqs)
win_freqs
table(win_freqs)
champions <- sort(win_freqs, decreasing = TRUE)
champions
barplot(champions)
# try this command
barplot(champions, las = 2)
barplot(champions)
barplot(champions, las = 2)
# try this other command
op <- par(mar = c(2, 11, 1, 2))
barplot(champions, horiz = TRUE, las = 2)
par(op)
year
winner
year[winner == "San Francisco 49ers"]
winner == "San Francisco 49ers"
year[winner == "Oakland Raiders"]
tail(year[winner == "Oakland Raiders"],1)
head(loser, 5)
tail(loser, 5)
loser[evenSeq]
loser[oddSeq]
los_freqs <- table(loser)
los_freqs
which.max(los_freqs)
max(los_freqs)
length(union(winner, loser))
setdiff(winner, loser)
?setdiff
setdiff(loser, winner)
# teams that have played the superbowl (both won and lost)?
union(winner, loser)
length(intersect(winner, loser))
winner["2000"]
winner[2000]
winner[year == 2000]
loser[year == 2000]
winner[year == "1970" | year == "1980" | year == "1990" | year == "2000" | year == "2010"]
winner[which(year >= 1970 & year <= 1979)]
loser[which(year >= 1990 & year <= 1999)]
superbowl_df <- data.frame(year, winner, loser)
superbowl <- list(year, winner, loser)
superbowl <- list(year, winner, loser)
getwd()
getwd()
setwd("/Users/Shulin/programming/stat133/lab03")
getwd()
getwd()
setwd("/Users/Shulin/programming/stat133/lab03")
states <- read.table(file = "states.txt", header = TRUE)
states <- read.table(file = "states.txt", header = TRUE)
states <- read.table(file = "states.txt", header = TRUE)
# inspect states using the following functions:
str(states)
states
dim(states)
summary(states)
View(states)
?read.table
# Here's one option to read the data in R
url <- "http://www.esapubs.org/archive/ecol/E084/094/MOMv3.3.txt"
df <- read.table(file = url, header = FALSE,
sep = "\t", na.strings = -999)
# Instead of read.table() what other function could you use?
df <- read.delim(file = url, na.strings = -999)
# inspect df using the following functions:
str(df)
dim(df)
nrow(df)
ncol(df)
head(df)
tail(df)
summary(df)
head(df)
View(df)
View(df)
head(df,1)
str(df)
dim(df)
nrow(df)
ncol(df)
head(df)
#if you want to get the first 3, use head(df,3)
tail(df)
summary(df)
df_names <- c('continent', 'status', 'order', 'family', 'genus',
'species', 'logmass', 'combmass', 'reference')
df2 <- read.delim(file = url, na.strings = -999,
nrows = 100, col.names = df_names)
str(df2, vec.len = 1)
head(df2)
summary(df2)
head(df2, 5)
head(df2, 3)
df_names <- c('continent', 'status', 'order', 'family', 'genus',
'species', 'logmass', 'combmass', 'reference')
df2 <- read.delim(file = url, na.strings = -999,
nrows = 100, col.names = df_names)
str(df2, vec.len = 1)
head(df2)
summary(df2)
View(df2)
View(df2)
unique(df2.species)
unique(df2["species"])
unique(df["species"])
2
unique(df2["species"])
unique(df2["species"])
count(unique(df2["species"]))
unique(df2["species"]).count
length(unique(df2["species"]))
length(unique(df2["species"]))
class(unique(df2["species"]))
unique(df2["species"])
nrow(unique(df2["species"]))
nrow(unique(df2["species"]))
nrow(unique(df2["species"]))
nrow(!unique(df2["species"]))
nrow(unique(df2["species"]))
nrow(unique(df2["species"]))
df2["continents"]
df2["continents"]
df2["continent"]
unique(df2["continent"])
length(unique(df2$species))
unique(df2["continent"])
df2$reference <- NULL
unique(df2["continent"])
length(unique(df2["species"]))
length(unique(df2[,"species"]))
df2$reference <- NULL
# create a new variable 'log2mass' (log base 2 of combmass)
df2$log2mass <- log(df2$combmass)
fish_url <- "http://datadryad.org/bitstream/handle/10255/dryad.34127/Brac%202006%20-%20fish%20data.txt?sequence=1"
fish <- read_tsv(fish_url, col_names = TRUE, skip = 1)
# inspect df using the following functions:
str(fish)
fish_url <- "http://datadryad.org/bitstream/handle/10255/dryad.34127/Brac%202006%20-%20fish%20data.txt?sequence=1"
fish <- read_tsv(fish_url, col_names = TRUE, skip = 1)
fish_url <- "http://datadryad.org/bitstream/handle/10255/dryad.34127/Brac%202006%20-%20fish%20data.txt?sequence=1"
fish <- read_tsv(fish_url, col_names = TRUE, skip = 1)
# =====================================================
# Data: "Brac 2006 - fish data"
# =====================================================
# Source: http://datadryad.org/handle/10255/dryad.34126
# Reference:
#   Sizling et al. (2011)
#   Between geometry and biology: the problem of universality
#   of the species-area relationship.
#   The American Naturalist 178(5): 602-611.
# URL: http://datadryad.org/bitstream/handle/10255/dryad.34127/Brac%202006%20-%20fish%20data.txt?sequence=1
# Go to the URL of the data
# What's the field delimiter?
# Is there a column header?
# Are there any lines to be skipped?
# How would you import the data in file "Brac 2006 - fish data"?
fish_url <- "http://datadryad.org/bitstream/handle/10255/dryad.34127/Brac%202006%20-%20fish%20data.txt?sequence=1"
fish <- read_tsv(fish_url, col_names = TRUE, skip = 1)
# inspect df using the following functions:
str(fish)
fish <- read_tsv(fish_url, col_names = TRUE, skip = 1)
fish <- read_tsv(fish_url, col_names = TRUE, skip = 1)
fish_url <- "http://datadryad.org/bitstream/handle/10255/dryad.34127/Brac%202006%20-%20fish%20data.txt?sequence=1"
fish <- read_tsv(fish_url, col_names = TRUE, skip = 1)
install.packages("readr")
library(readr)
fish_url <- "http://datadryad.org/bitstream/handle/10255/dryad.34127/Brac%202006%20-%20fish%20data.txt?sequence=1"
fish <- read_tsv(fish_url, col_names = TRUE, skip = 1)
#install.packages("readr") in order to make read_tsv work
fish_url <- "http://datadryad.org/bitstream/handle/10255/dryad.34127/Brac%202006%20-%20fish%20data.txt?sequence=1"
fish <- read_tsv(fish_url, col_names = TRUE, skip = 1)
# inspect df using the following functions:
str(fish)
dim(fish)
nrow(fish)
ncol(fish)
head(fish)
tail(fish)
summary(fish)
#what are the column names?
View(fish)
View(fish)
colnames(fish)
length(unique(fish$Species))
length(unique(fish$Species))
fish$Day
max(fish$day)
max(fish$Day)
unique(fish$Day)
length(unique(fish$Day))
max(fish$Day) - min(fish$Day)
max(fish$Day) - min(fish$Day)
max(fish$Day) - min(fish$Day) + 1
max(length(fish$Day))
fish$Day
length(fish$Day == 1)
length(fish$Day == 2)
length(fish$Day == '2')
length(fish['Day'] == 1)
fish['Day'] == 1
length((fish['Day'] == 1) == TRUE)
length((fish['Day'] == 1) == TRUE)
fish['Day'] == 1
?numrows
?nrow
day1 <- c(fish['Day'] == 1)
length(day1)
day1 <- c(fish['Day'] == 1)
day1
length(day1[day1$DAY==1])
length(day1[day1$Day==1])
nrow(subset(fish, Day=1))
nrow(subset(fish, Day=2))
?which
fish[Day==1]
subset(fish, Day == 1)
subset(fish, Day == 1)
length(subset(fish, Day == 1))
subset(fish, Day == 1)
nrows(subset(fish, Day == 1))
nrow(subset(fish, Day == 1))
table(fish)
table(fish$Day)
class(table(fish$Day))
table(fish$Day)
a = t[order(row)]
a = t[order(row=1)]
sort(t)
sort(table(fish$Day), decreasing = TRUE)
sort(table(fish$Day), decreasing = TRUE)[0]
t <- sort(table(fish$Day), decreasing = TRUE)
t[0]
t[1]
t[1,1]
class(t)
t <- sort(table(fish$Day), decreasing = TRUE)
t[1]
# =====================================================
# Data: SF Open Data "Permit Types"
# =====================================================
# Source: https://data.sfgov.org/City-Infrastructure/Permit-Types/6wa6-8527
# Reference:
#   SF Open Data
# URL: https://data.sfgov.org/City-Infrastructure/Permit-Types/6wa6-8527
# Go to the link of the data
# The data "Permit Types" can be downloaded in several ways
# Click the "Export" button in the menu bar to see those options
# The goal is to read the data in CSV format
permits_url <- "https://data.sfgov.org/api/views/6wa6-8527/rows.csv"
# try to use read.csv() and see what happens
permits <- read.csv(permits_url)
# the problem has to do with the Secured HTTP url (i.e. "https://...")
# read.csv() cannot handle 'https'
# OPTION 1
# One solution is to download the file to your computer
# and then use read.csv()
# Assuming that the downloaded file is in your working directory:
pt <- read.csv("Permit_Types.csv")
# OPTION 2
# Instead of downloading the file, we can read it directly in R
# One solution is to use the package RCurl
# (remember to install it first)
library(RCurl)
t <- sort(table(fish$Day), decreasing = TRUE)
t <- sort(table(fish$Day), decreasing = TRUE)
t[1]
install.packages("RCurl")
# (remember to install it first)
install.packages("RCurl")
library(RCurl)
library(RCurl)
# URL of data file
perms_url <- getURL(permits_url)
# import data in R (through a text connection)
perms <- read.csv(textConnection(perms_url))
View(perms)
View(perms)
head(perms)
# OPTION 3 (my preferred one)
# Another solution is to use the package 'readr'
# (if you don't have it yet, remember to install it first)
library(readr)
permits <- read_csv(permits_url)
head(permits)
class(t[1])
t[1]
t[1][0]
t[1]
t <- sort(table(fish$Day), decreasing = TRUE)
t
names(t[1])
class(names(t[1]))
class(t)
names(t[1])
t <- sort(table(fish$Day), decreasing = TRUE)
names(t[1])
# =====================================================
# Data: SF Open Data "Permit Types"
# =====================================================
# Source: https://data.sfgov.org/City-Infrastructure/Permit-Types/6wa6-8527
# Reference:
#   SF Open Data
# URL: https://data.sfgov.org/City-Infrastructure/Permit-Types/6wa6-8527
# Go to the link of the data
# The data "Permit Types" can be downloaded in several ways
# Click the "Export" button in the menu bar to see those options
# The goal is to read the data in CSV format
permits_url <- "https://data.sfgov.org/api/views/6wa6-8527/rows.csv"
# try to use read.csv() and see what happens
permits <- read.csv(permits_url)
# the problem has to do with the Secured HTTP url (i.e. "https://...")
# read.csv() cannot handle 'https'
# OPTION 1
# One solution is to download the file to your computer
# and then use read.csv()
# Assuming that the downloaded file is in your working directory:
pt <- read.csv("Permit_Types.csv")
# OPTION 2
# One solution is to use the package RCurl
# Instead of downloading the file, we can read it directly in R
# (remember to install it first)
install.packages("RCurl")
library(RCurl)
# URL of data file
perms_url <- getURL(permits_url)
# import data in R (through a text connection)
perms <- read.csv(textConnection(perms_url))
head(perms)
# OPTION 3 (my preferred one)
# Another solution is to use the package 'readr'
source('~/programming/stat133/lab03/lab03.R')
source('~/programming/stat133/lab03/lab03.R', echo=TRUE)
